{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6eb10ebc",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "6eb10ebc",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b92db13317f0e6015961bb08b3e82abe",
          "grade": false,
          "grade_id": "cell-5cf52405126f2776",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# Python File Objects"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dde64ab9",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "dde64ab9",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a387926e4abf68d9b2700ae2a55753ff",
          "grade": false,
          "grade_id": "cell-c7eab4c0d23e582f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Complete the programming exercises below.\n",
        "* Delete or comment out the line of code in each cell which says `raise NotImplementedError()` and replace it with your own.\n",
        "\n",
        "### Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d585affc",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "d585affc",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5883ccb9de705b4500eda96036feedf3",
          "grade": false,
          "grade_id": "cell-e901448fcdc0d1d8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Path to file or directory\n",
        "\n",
        "Sometimes you want to work with files in a particular directory. In order to do that you need to get the path. There are a couple different ways you can do that.\n",
        "\n",
        "In Windows you can open a command prompt (in Mac a terminal window) and drag the file or folder to the command prompt and the path will display in the window. You can then copy the path and paste it into your code. It will probably look something like this.\n",
        "\n",
        "`C:\\Users\\UserName\\Documents`\n",
        "\n",
        "To use the path in your code, you will want to assign it to a variable.\n",
        "\n",
        "`file_path = 'C:\\Users\\UserName\\Documents'`\n",
        "\n",
        "Windows users will quickly realize that their path as Windows formats it causes error when used without some modification. (Mac users won't have this problem because Macs format the path in a way that Python can use it without modification.) This is a problem for Windows users because Windows uses backslash (\\) characters in the file path. In Python, the backslash character is a special character. To use special characters in strings in Python, they need to have an escape character added before the special character. In Python, the escape character is the backslash (\\). One option Windows users have is to add an extra backslash in front of every backslash in the path. It will look like this.\n",
        "\n",
        "`file_path = 'C:\\\\Users\\\\UserName\\\\Documents'`\n",
        "\n",
        "Another option is to change each backslash (\\) to a forward slash (/).\n",
        "\n",
        "`file_path = 'C:/Users/UserName/Documents'`\n",
        "\n",
        "Another option is to format the string as a raw string. This option saves a lot of typing. This is done in Python by adding a lowercase `r` in front of the quotation marks for the string. This is a signal to Python to treat the string exactly as it is formatted and consider any special characters included in the string as literal characters.\n",
        "\n",
        "`file_path = r'C:\\Users\\UserName\\Documents'`\n",
        "\n",
        "Another option is to use a graphical user interface included in Python (called tkinter) to open a dialog window and allow the user to select the file or directory of interest. Run the code block below to use the file dialog to select the files directory included in the repository for this assignment. (Be sure to select the inner files directory which actually contains the files needed for the assignment.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BCX3IW8oVe_S",
      "metadata": {
        "id": "BCX3IW8oVe_S"
      },
      "source": [
        "## Use this code with Google Colab\n",
        "\n",
        "The code blocks in this section with clone the GitHub repository and extrac the files you need from the zip archive. (A zip archive is a compressed folder that contains other files. The files need to be extracted before they can be used.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fakKJK4WTRQB",
      "metadata": {
        "id": "fakKJK4WTRQB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: Too many arguments.\n",
            "\n",
            "usage: git clone [<options>] [--] <repo> [<dir>]\n",
            "\n",
            "    -v, --[no-]verbose    be more verbose\n",
            "    -q, --[no-]quiet      be more quiet\n",
            "    --[no-]progress       force progress reporting\n",
            "    --[no-]reject-shallow don't clone shallow repository\n",
            "    -n, --no-checkout     don't create a checkout\n",
            "    --checkout            opposite of --no-checkout\n",
            "    --[no-]bare           create a bare repository\n",
            "    --[no-]mirror         create a mirror repository (implies --bare)\n",
            "    -l, --[no-]local      to clone from a local repository\n",
            "    --no-hardlinks        don't use local hardlinks, always copy\n",
            "    --hardlinks           opposite of --no-hardlinks\n",
            "    -s, --[no-]shared     setup as shared repository\n",
            "    --[no-]recurse-submodules[=<pathspec>]\n",
            "                          initialize submodules in the clone\n",
            "    --[no-]recursive ...  alias of --recurse-submodules\n",
            "    -j, --[no-]jobs <n>   number of submodules cloned in parallel\n",
            "    --[no-]template <template-directory>\n",
            "                          directory from which templates will be used\n",
            "    --[no-]reference <repo>\n",
            "                          reference repository\n",
            "    --[no-]reference-if-able <repo>\n",
            "                          reference repository\n",
            "    --[no-]dissociate     use --reference only while cloning\n",
            "    -o, --[no-]origin <name>\n",
            "                          use <name> instead of 'origin' to track upstream\n",
            "    -b, --[no-]branch <branch>\n",
            "                          checkout <branch> instead of the remote's HEAD\n",
            "    -u, --[no-]upload-pack <path>\n",
            "                          path to git-upload-pack on the remote\n",
            "    --[no-]depth <depth>  create a shallow clone of that depth\n",
            "    --[no-]shallow-since <time>\n",
            "                          create a shallow clone since a specific time\n",
            "    --[no-]shallow-exclude <revision>\n",
            "                          deepen history of shallow clone, excluding rev\n",
            "    --[no-]single-branch  clone only one branch, HEAD or --branch\n",
            "    --no-tags             don't clone any tags, and make later fetches not to follow them\n",
            "    --tags                opposite of --no-tags\n",
            "    --[no-]shallow-submodules\n",
            "                          any cloned submodules will be shallow\n",
            "    --[no-]separate-git-dir <gitdir>\n",
            "                          separate git dir from working tree\n",
            "    --[no-]ref-format <format>\n",
            "                          specify the reference format to use\n",
            "    -c, --[no-]config <key=value>\n",
            "                          set config inside the new repository\n",
            "    --[no-]server-option <server-specific>\n",
            "                          option to transmit\n",
            "    -4, --ipv4            use IPv4 addresses only\n",
            "    -6, --ipv6            use IPv6 addresses only\n",
            "    --[no-]filter <args>  object filtering\n",
            "    --[no-]also-filter-submodules\n",
            "                          apply partial clone filters to submodules\n",
            "    --[no-]remote-submodules\n",
            "                          any cloned submodules will use their remote-tracking branch\n",
            "    --[no-]sparse         initialize sparse-checkout file to include only files at root\n",
            "    --[no-]bundle-uri <uri>\n",
            "                          a URI for downloading bundles before fetching from origin remote\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Ammrun/exerPythCombineFiles.git # replace the address shown with the address to your own repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4RpiJpKFTk4e",
      "metadata": {
        "id": "4RpiJpKFTk4e"
      },
      "outputs": [],
      "source": [
        "zip_path = 'C:/Users/ammar/OneDrive/Desktop/exerPythCombineFiles-master/exerPythCombineFiles-master/FileTypes.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "BnuEOTw-UPPG",
      "metadata": {
        "id": "BnuEOTw-UPPG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(zip_path, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c-rc2tmsV9GS",
      "metadata": {
        "id": "c-rc2tmsV9GS"
      },
      "outputs": [],
      "source": [
        "# Get the path to the directory with the extracted files\n",
        "file_path = 'C:/Users/ammar/OneDrive/Desktop/exerPythCombineFiles-master/exerPythCombineFiles-master/FileTypes'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eRgyPdbSWN3w",
      "metadata": {
        "id": "eRgyPdbSWN3w"
      },
      "source": [
        "## Skip this code block if you're using Google Colab\n",
        "\n",
        "This code block is used if you're working with files on your own computer. You can skip it if you're using Google Colab and you completed the steps above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6cbe2b94",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "6cbe2b94",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "feca7292f76a7194a482af7131a209a0",
          "grade": false,
          "grade_id": "cell-183af8e202482f24",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Opening dialogue box for folder selection. Please choose a folder.\n",
            "Folder selected:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Have user select the folder with the needed files.\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog\n",
        "\n",
        "root = tk.Tk()\n",
        "root.lift()\n",
        "root.withdraw()\n",
        "\n",
        "# This code block will open a specific file. (Uncomment the lines after this comment to use them.)\n",
        "#print('Opening dialogue box for file selection. Please choose a file.')\n",
        "#file_path = filedialog.askopenfilename()\n",
        "#print('File selected:')\n",
        "\n",
        "# This code block will get a directory path. (Uncomment the lines after this comment to use them.)\n",
        "print('Opening dialogue box for folder selection. Please choose a folder.')\n",
        "file_path = filedialog.askdirectory()\n",
        "print('Folder selected:')\n",
        "\n",
        "print(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c25e136f",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "c25e136f",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "53909d360d9af048066cffc30634b1a6",
          "grade": false,
          "grade_id": "cell-d16626c0c6bbe05e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Working with different file types in Python\n",
        "\n",
        "The purpose of this assignment is to see how to work with different file types in Python. Run the code block below to see the different types of files included in the folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d79836bd",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "d79836bd",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1b4b1b7e9b0f816a028b9aa9ecbb3e56",
          "grade": false,
          "grade_id": "cell-63ec098105c6360f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All files in folder:  ['Combine multiple file types with same columns into dataframe.ipynb', 'Combine multiple file types with same columns into dataframe.py', 'CSVtest.csv', 'CSVtest2.csv', 'EXCELtest.xlsx', 'EXCELtest2.xlsx', 'JSONtest.json', 'JSONtest2.json', 'JSONtest3.json', 'XMLtest.xml', 'XMLtest2.xml', 'XMLtest3.xml'] \n",
            "\n",
            "CSV files:  ['CSVtest.csv', 'CSVtest2.csv'] \n",
            "Excel files:  ['EXCELtest.xlsx', 'EXCELtest2.xlsx'] \n",
            "JSON files:  ['JSONtest.json', 'JSONtest2.json', 'JSONtest3.json'] \n",
            "XML files:  ['XMLtest.xml', 'XMLtest2.xml', 'XMLtest3.xml']\n"
          ]
        }
      ],
      "source": [
        "# Make sure correct files are recognized.\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# List the files in the directory.\n",
        "files = os.listdir(file_path)\n",
        "print('All files in folder: ', files, '\\n')\n",
        "\n",
        "# List of file types we want to add\n",
        "file_types = ['xlsx','csv','json','xml']\n",
        "\n",
        "# create a list of files for each file type\n",
        "files_csv = [f for f in files if f[-3:] == 'csv']\n",
        "files_xlsx = [f for f in files if f[-4:] == 'xlsx']\n",
        "files_json = [f for f in files if f[-4:] == 'json']\n",
        "files_xml = [f for f in files if f[-3:] == 'xml']\n",
        "\n",
        "print('CSV files: ', files_csv, '\\nExcel files: ', files_xlsx, '\\nJSON files: ',files_json, '\\nXML files: ', files_xml)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41ecb133",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "41ecb133",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "036cbdaf3fccb0cf6e64a982dc89dd48",
          "grade": false,
          "grade_id": "cell-a6b8c71f6b3c4122",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Write your answers as comments in the cell below.\n",
        "\n",
        "* What types of files are included in the folder? List the file extensions and how many of each type you see."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b231323f",
      "metadata": {
        "deletable": false,
        "id": "b231323f",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "411e33553ef624d8113dc68030dcd2e7",
          "grade": true,
          "grade_id": "cell-2e7557a700ca381e",
          "locked": false,
          "points": 2,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "#2 CSV files\n",
        "#2 Excel files\n",
        "#3 Json files\n",
        "#3 XML files"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b39c2827",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "b39c2827",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "616728e37e1fc6e8975a812b35ba637d",
          "grade": false,
          "grade_id": "cell-49ef237b3b87c9ef",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Creating a Pandas dataframe\n",
        "\n",
        "Run the code block below to read each data file and combine them into a Pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "fe8ee1d1",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "fe8ee1d1",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "63101f07169f46ab9e272e861b050aff",
          "grade": false,
          "grade_id": "cell-777c52aa20d58ca8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openpyxl\n",
            "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting et-xmlfile (from openpyxl)\n",
            "  Downloading et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
            "Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: et-xmlfile, openpyxl\n",
            "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.5\n",
            "Requirement already satisfied: requests in c:\\users\\ammar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ammar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ammar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ammar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ammar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2024.8.30)\n",
            "14\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>date</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jack Smith</td>\n",
              "      <td>4/1/2019</td>\n",
              "      <td>185</td>\n",
              "      <td>91</td>\n",
              "      <td>CSVtest.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jack Black</td>\n",
              "      <td>4/2/2019</td>\n",
              "      <td>183</td>\n",
              "      <td>91</td>\n",
              "      <td>CSVtest.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Brock Bricks</td>\n",
              "      <td>4/10/2019</td>\n",
              "      <td>185</td>\n",
              "      <td>95</td>\n",
              "      <td>CSVtest2.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jack Brack</td>\n",
              "      <td>6/7/2019</td>\n",
              "      <td>172</td>\n",
              "      <td>91</td>\n",
              "      <td>CSVtest2.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jen Smith</td>\n",
              "      <td>2019-05-02 00:00:00</td>\n",
              "      <td>153</td>\n",
              "      <td>50</td>\n",
              "      <td>EXCELtest.xlsx</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Sam Smith</td>\n",
              "      <td>2019-01-02 00:00:00</td>\n",
              "      <td>160</td>\n",
              "      <td>55</td>\n",
              "      <td>EXCELtest.xlsx</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Rock Royden</td>\n",
              "      <td>2019-05-02 00:00:00</td>\n",
              "      <td>160</td>\n",
              "      <td>52</td>\n",
              "      <td>EXCELtest2.xlsx</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Brandon Snads</td>\n",
              "      <td>2019-10-02 00:00:00</td>\n",
              "      <td>175</td>\n",
              "      <td>80</td>\n",
              "      <td>EXCELtest2.xlsx</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Jane Smith</td>\n",
              "      <td>09/02/2019</td>\n",
              "      <td>170</td>\n",
              "      <td>75</td>\n",
              "      <td>JSONtest.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Jane Jackson</td>\n",
              "      <td>09/03/2019</td>\n",
              "      <td>172</td>\n",
              "      <td>74</td>\n",
              "      <td>JSONtest2.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Becky Jackson</td>\n",
              "      <td>04/03/2019</td>\n",
              "      <td>165</td>\n",
              "      <td>70</td>\n",
              "      <td>JSONtest3.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>John Smith</td>\n",
              "      <td>02/08/2019</td>\n",
              "      <td>180</td>\n",
              "      <td>100</td>\n",
              "      <td>XMLtest.xml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>John Smithe</td>\n",
              "      <td>03/08/2019</td>\n",
              "      <td>185</td>\n",
              "      <td>101</td>\n",
              "      <td>XMLtest2.xml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Brett Smithe</td>\n",
              "      <td>05/08/2019</td>\n",
              "      <td>179</td>\n",
              "      <td>99</td>\n",
              "      <td>XMLtest3.xml</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             name                 date height weight           Source\n",
              "0      Jack Smith             4/1/2019    185     91      CSVtest.csv\n",
              "1      Jack Black             4/2/2019    183     91      CSVtest.csv\n",
              "2    Brock Bricks            4/10/2019    185     95     CSVtest2.csv\n",
              "3      Jack Brack             6/7/2019    172     91     CSVtest2.csv\n",
              "4       Jen Smith  2019-05-02 00:00:00    153     50   EXCELtest.xlsx\n",
              "5       Sam Smith  2019-01-02 00:00:00    160     55   EXCELtest.xlsx\n",
              "6     Rock Royden  2019-05-02 00:00:00    160     52  EXCELtest2.xlsx\n",
              "7   Brandon Snads  2019-10-02 00:00:00    175     80  EXCELtest2.xlsx\n",
              "8      Jane Smith           09/02/2019    170     75    JSONtest.json\n",
              "9    Jane Jackson           09/03/2019    172     74   JSONtest2.json\n",
              "10  Becky Jackson           04/03/2019    165     70   JSONtest3.json\n",
              "11     John Smith           02/08/2019    180    100      XMLtest.xml\n",
              "12    John Smithe           03/08/2019    185    101     XMLtest2.xml\n",
              "13   Brett Smithe           05/08/2019    179     99     XMLtest3.xml"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "#!pip install openpyxl\n",
        "#!pip install requests\n",
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Iterate through the files in the directory and append each one into the dataframe.\n",
        "# This will only work correctly if the files have the exact same column names.\n",
        "df_list = []\n",
        "for f in files_csv:\n",
        "    data = pd.read_csv(str(file_path) + '/' + str(f), index_col=None, header=0)\n",
        "    data['Source'] = f\n",
        "    df_list.append(data)\n",
        "\n",
        "for f in files_xlsx:\n",
        "    data = pd.read_excel(str(file_path) + '/' + str(f))\n",
        "    data['Source'] = f\n",
        "    df_list.append(data)\n",
        "\n",
        "# Iterate through the json files and add data from each to a list.\n",
        "json_list = []\n",
        "for f in files_json:\n",
        "    with open(str(file_path) + '/' + str(f)) as json_file:\n",
        "        json_obj = json.load(json_file)\n",
        "        json_obj['Source'] = f\n",
        "        json_list.append(json_obj.copy())\n",
        "# Turn the combined list into a dataframe.\n",
        "data = pd.DataFrame(json_list)\n",
        "# Add the data frame to the list of dataframes.\n",
        "df_list.append(data)\n",
        "\n",
        "# Iterate through the xml files and add data from each to a list.\n",
        "xml_list = []\n",
        "for f in files_xml:\n",
        "    # create element tree object\n",
        "    tree = ET.parse(str(file_path) + '/' + str(f))\n",
        "    # get root element\n",
        "    root = tree.getroot()\n",
        "    # create dictionary from XML tags and values\n",
        "    itemdict = {}\n",
        "    for item in root:\n",
        "        itemdict[item.tag] = item.text\n",
        "    itemdict['Source'] = f\n",
        "    xml_list.append(itemdict.copy())\n",
        "# Turn the combined list into a dataframe.\n",
        "data = pd.DataFrame(xml_list)\n",
        "# Add the data frame to the list of dataframes.\n",
        "df_list.append(data)\n",
        "\n",
        "# Combine all the data frames in the list into a single data frame.\n",
        "df =  pd.concat(df_list, axis=0, ignore_index=True, sort=False)\n",
        "\n",
        "# See how many rows the data frame has.\n",
        "print(len(df.index))\n",
        "\n",
        "# Show the data in the data frame.\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9bcfaa3",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "b9bcfaa3",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5ffe1ee85e9a932d57ef6708d9ad2780",
          "grade": false,
          "grade_id": "cell-fc20f8a537557818",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Saving a dataframe to csv\n",
        "\n",
        "Run the code block below to save your new dataframe as a csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "1e3e5a7d",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "1e3e5a7d",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d63ff84c0c6a7b1c4499c1320a82db65",
          "grade": false,
          "grade_id": "cell-8f820404d1d343ed",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-10-17\n",
            "C:/Users/ammar/OneDrive/Desktop/exerPythCombineFiles-master/exerPythCombineFiles-master/FileTypes/NewCombinedFile_2024-10-17.csv\n",
            "File saved.\n"
          ]
        }
      ],
      "source": [
        "# Save the dataframe to a new combined csv file.\n",
        "\n",
        "# Add today's date to the name of the new file.\n",
        "from datetime import date\n",
        "today = date.today()\n",
        "print(today)\n",
        "\n",
        "filename = str(file_path) + '/' + 'NewCombinedFile_' + str(today) + '.csv'\n",
        "print(filename)\n",
        "\n",
        "df.to_csv(filename, index=False)\n",
        "print('File saved.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96b2f34c",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "96b2f34c",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5caccc71a46288d22884f19f41ba45a2",
          "grade": false,
          "grade_id": "cell-ffeacc8e7cac213c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Create additional data files\n",
        "\n",
        "Create a new data file for each type included in the folder. (You can use Excel to modify the content in the .xlsx and .csv files and save them under a new name in the same folder. You can use VSCode or Notepad++ to modify the content of an .xml and .json file and save those under a new name in the same folder.) Make sure you create at least one additional file for each type of data file in the folder."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "607b9aa6",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "607b9aa6",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "85db0e5d334b3bfe20b64a4ec1e4c372",
          "grade": false,
          "grade_id": "cell-e54523c23d0f01c1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Enter code in the cell below.\n",
        "\n",
        "* Create a variable called `file_path` which contains the path to the folder where all the data files are included. You can use any of the methods described at the beginning of the notebook (Manually copy the path or copy the code to create a file dialog to choose the correct folder.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e2fa0776",
      "metadata": {
        "deletable": false,
        "id": "e2fa0776",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "361e07929d306cd9e8fa4c5ae3709b63",
          "grade": true,
          "grade_id": "cell-9e46a40a2a029afd",
          "locked": false,
          "points": 2,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "file_path = 'C:/Users/ammar/OneDrive/Desktop/exerPythCombineFiles-master/exerPythCombineFiles-master/FileTypes/RevisedFiles'\n",
        "#raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4386fdd2",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "4386fdd2",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0ae36a589a1d7966b8ab3678102011b5",
          "grade": false,
          "grade_id": "cell-be96adc4fbda881b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Enter code in the cell below.\n",
        "\n",
        "* Add code in the cell below to list the files in the folder and create lists for each data file type. (Hint - It's OK to reuse code from earlier in the assignment.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a650faed",
      "metadata": {
        "deletable": false,
        "id": "a650faed",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4510ca612c9ad4a08f90022eeb4db8fa",
          "grade": true,
          "grade_id": "cell-53ce4edf792e3627",
          "locked": false,
          "points": 2,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All files in folder:  ['CSVtestREVISED.csv', 'EXCELtestREVISED.xlsx', 'JSONtestREVISED.json', 'XMLtestREVISED.xml'] \n",
            "\n",
            "CSV files:  ['CSVtestREVISED.csv'] \n",
            "Excel files:  ['EXCELtestREVISED.xlsx'] \n",
            "JSON files:  ['JSONtestREVISED.json'] \n",
            "XML files:  ['XMLtestREVISED.xml']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# List the files in the directory.\n",
        "files = os.listdir(file_path)\n",
        "print('All files in folder: ', files, '\\n')\n",
        "\n",
        "# List of file types we want to add\n",
        "file_types = ['xlsx','csv','json','xml']\n",
        "\n",
        "# create a list of files for each file type\n",
        "files_csv = [f for f in files if f[-3:] == 'csv']\n",
        "files_xlsx = [f for f in files if f[-4:] == 'xlsx']\n",
        "files_json = [f for f in files if f[-4:] == 'json']\n",
        "files_xml = [f for f in files if f[-3:] == 'xml']\n",
        "\n",
        "print('CSV files: ', files_csv, '\\nExcel files: ', files_xlsx, '\\nJSON files: ',files_json, '\\nXML files: ', files_xml)\n",
        "#raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e56b6eda",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "e56b6eda",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3e299951d3b6ac2081e24406a31a7bbf",
          "grade": false,
          "grade_id": "cell-9046144d63ad9faf",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Write you answers as comments in the cell below.\n",
        "\n",
        "* What types of files are included in the folder? List the file extensions and how many of each type you see."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e93c2e7b",
      "metadata": {
        "deletable": false,
        "id": "e93c2e7b",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2e46c44126e2c3d6d31e4f855cca05c1",
          "grade": true,
          "grade_id": "cell-b396c8c422e37b42",
          "locked": false,
          "points": 2,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# YOUR CODE HERE\n",
        "#1 CSV file\n",
        "#1Excel File\n",
        "#1Json file\n",
        "#1XML file\n",
        "raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f32084d2",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "f32084d2",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ceae4851ebc21a84a51f27ed084ea1d8",
          "grade": false,
          "grade_id": "cell-ac79fbd19d488577",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Enter code in the cell below.\n",
        "\n",
        "* Add code in the cell below to read each data file and combine them into a Pandas dataframe and display the dataframe. (Hint - It's OK to reuse code from earlier in the assignment.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "de01933e",
      "metadata": {
        "deletable": false,
        "id": "de01933e",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8a1dbfe4b4958235b306d12cf4d59785",
          "grade": true,
          "grade_id": "cell-c2d07cf21cd676a1",
          "locked": false,
          "points": 2,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>date</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ammaron</td>\n",
              "      <td>4/1/2019</td>\n",
              "      <td>185</td>\n",
              "      <td>91</td>\n",
              "      <td>CSVtestREVISED.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Allison</td>\n",
              "      <td>4/2/2019</td>\n",
              "      <td>183</td>\n",
              "      <td>91</td>\n",
              "      <td>CSVtestREVISED.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mike</td>\n",
              "      <td>2019-05-02 00:00:00</td>\n",
              "      <td>153</td>\n",
              "      <td>50</td>\n",
              "      <td>EXCELtestREVISED.xlsx</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Edward</td>\n",
              "      <td>2019-01-02 00:00:00</td>\n",
              "      <td>160</td>\n",
              "      <td>55</td>\n",
              "      <td>EXCELtestREVISED.xlsx</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Weird Name 1</td>\n",
              "      <td>09/02/2019</td>\n",
              "      <td>170</td>\n",
              "      <td>75</td>\n",
              "      <td>JSONtestREVISED.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Same Name</td>\n",
              "      <td>02/08/2019</td>\n",
              "      <td>180</td>\n",
              "      <td>100</td>\n",
              "      <td>XMLtestREVISED.xml</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           name                 date height weight                 Source\n",
              "0       Ammaron             4/1/2019    185     91     CSVtestREVISED.csv\n",
              "1       Allison             4/2/2019    183     91     CSVtestREVISED.csv\n",
              "2          Mike  2019-05-02 00:00:00    153     50  EXCELtestREVISED.xlsx\n",
              "3        Edward  2019-01-02 00:00:00    160     55  EXCELtestREVISED.xlsx\n",
              "4  Weird Name 1           09/02/2019    170     75   JSONtestREVISED.json\n",
              "5     Same Name           02/08/2019    180    100     XMLtestREVISED.xml"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "import json\n",
        "#!pip install openpyxl\n",
        "#!pip install requests\n",
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Iterate through the files in the directory and append each one into the dataframe.\n",
        "# This will only work correctly if the files have the exact same column names.\n",
        "df_list = []\n",
        "for f in files_csv:\n",
        "    data = pd.read_csv(str(file_path) + '/' + str(f), index_col=None, header=0)\n",
        "    data['Source'] = f\n",
        "    df_list.append(data)\n",
        "\n",
        "for f in files_xlsx:\n",
        "    data = pd.read_excel(str(file_path) + '/' + str(f))\n",
        "    data['Source'] = f\n",
        "    df_list.append(data)\n",
        "\n",
        "# Iterate through the json files and add data from each to a list.\n",
        "json_list = []\n",
        "for f in files_json:\n",
        "    with open(str(file_path) + '/' + str(f)) as json_file:\n",
        "        json_obj = json.load(json_file)\n",
        "        json_obj['Source'] = f\n",
        "        json_list.append(json_obj.copy())\n",
        "# Turn the combined list into a dataframe.\n",
        "data = pd.DataFrame(json_list)\n",
        "# Add the data frame to the list of dataframes.\n",
        "df_list.append(data)\n",
        "\n",
        "# Iterate through the xml files and add data from each to a list.\n",
        "xml_list = []\n",
        "for f in files_xml:\n",
        "    # create element tree object\n",
        "    tree = ET.parse(str(file_path) + '/' + str(f))\n",
        "    # get root element\n",
        "    root = tree.getroot()\n",
        "    # create dictionary from XML tags and values\n",
        "    itemdict = {}\n",
        "    for item in root:\n",
        "        itemdict[item.tag] = item.text\n",
        "    itemdict['Source'] = f\n",
        "    xml_list.append(itemdict.copy())\n",
        "# Turn the combined list into a dataframe.\n",
        "data = pd.DataFrame(xml_list)\n",
        "# Add the data frame to the list of dataframes.\n",
        "df_list.append(data)\n",
        "\n",
        "# Combine all the data frames in the list into a single data frame.\n",
        "df =  pd.concat(df_list, axis=0, ignore_index=True, sort=False)\n",
        "\n",
        "# See how many rows the data frame has.\n",
        "print(len(df.index))\n",
        "\n",
        "# Show the data in the data frame.\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6328c230",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "6328c230",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d8069c1c76676e7fb2473f9734d61085",
          "grade": false,
          "grade_id": "cell-1f9b56443ee0fe56",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Enter code in the cell below.\n",
        "\n",
        "* Add code in the cell below to save your new dataframe as a csv file. (Hint - It's OK to reuse code from earlier in the assignment.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b9166a0c",
      "metadata": {
        "deletable": false,
        "id": "b9166a0c",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f2e3edce85e2bec2716893357ff5dcce",
          "grade": true,
          "grade_id": "cell-737b71ac218cd8c8",
          "locked": false,
          "points": 2,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-10-17\n",
            "C:/Users/ammar/OneDrive/Desktop/exerPythCombineFiles-master/exerPythCombineFiles-master/FileTypes/RevisedFiles/NewCombinedFile_2024-10-17.csv\n",
            "File saved.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Add today's date to the name of the new file.\n",
        "from datetime import date\n",
        "today = date.today()\n",
        "print(today)\n",
        "\n",
        "filename = str(file_path) + '/' + 'NewCombinedFile_' + str(today) + '.csv'\n",
        "print(filename)\n",
        "\n",
        "df.to_csv(filename, index=False)\n",
        "print('File saved.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E5XZBiEOYQxO",
      "metadata": {
        "id": "E5XZBiEOYQxO"
      },
      "source": [
        "# Push your updated files to GitHub\n",
        "\n",
        "If you're running this on Google Colab, you'll need to push your updated data files go GitHub and also upload your Jupyter Notebook with all of your output to your GitHub assignment repository. Instructions can be found at https://github.com/cmcntsh/OpenJupyterNBinGoogleColab\n",
        "\n",
        "Be sure to turn in the url to your GitHub repository in Canvas."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
